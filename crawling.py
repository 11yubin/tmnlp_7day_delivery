from dotenv import load_dotenv
import os
import psycopg2
from selenium import webdriver
import time
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime

def db_connect():
    load_dotenv()

    try:
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT"),
            dbname=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASSWORD")
        )
        print("âœ… ì—°ê²° ì„±ê³µ")
    except Exception as e:
        print("âŒ ì—°ê²° ì‹¤íŒ¨:", e)

def crawling():
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    query = "7ì¼ ë°°ì†¡"
    url = f"https://search.naver.com/search.naver?ssc=tab.news.all&query={query}&sm=tab_opt&sort=0&photo=0&field=0&pd=-1&ds=2025.05.21&de=2025.05.21&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=&is_sug_officeid=0&office_category=&service_area=1"
    driver.get(url)
    print("âœ… driver open")

    # for _ in range(20):
    #     driver.execute_script("window.scrollBy(0, 1500);")
    #     time.sleep(1)

    # ëê¹Œì§€ ìŠ¤í¬ë¡¤
    last_height = driver.execute_script("return document.body.scrollHeight")

    while True:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1.5)  # ë¡œë”© ì‹œê°„ ì—¬ìœ 

        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

        time.sleep(1)
    
    print("âœ… scroll complete")
    
    # time.sleep(100)

    links = []

    for i in range(1, 77):  # div[1] ~ div[15]
        for j in range(1, 10):
            try:
                if i==1:
                    xpath = f'/html/body/div[3]/div[2]/div[1]/div[1]/section/div[1]/div[2]/ul/div/div/div/div/div[{j}]/div[1]/div[1]/div[2]/span[4]/a'
                else:
                    xpath = f'/html/body/div[3]/div[2]/div[1]/div[1]/section/div[1]/div[2]/ul/div[{i}]/div/div/div/div[{j}]/div[1]/div[1]/div[2]/span[4]/a'
                
                element = driver.find_element(By.XPATH, xpath)
                href = element.get_attribute("href")
                links.append(href)

            except Exception as e:
                continue
        
            print(f"{i} page ì™„ë£Œ, ì´ {len(links)}")


    # link_elements = driver.find_elements(By.CSS_SELECTOR, "a.news_tit")
    # links = [elem.get_attribute("href") for elem in link_elements]

    print(f"ğŸ”— ìˆ˜ì§‘ëœ ë§í¬ ê°œìˆ˜: {len(links)}")
    # ì €ì¥
    news_links = pd.DataFrame({'id': range(len(links)), 'link': links})

    driver.quit()

    news_links.to_csv('links.csv')
    print("âœ… get links")

def main():
    links = pd.read_csv('./links.csv')
    link = links['link'][0]

    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    res = requests.get(link, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")

    # ì œëª©
    title = soup.select_one("h2.media_end_head_headline").text.strip()

    # ë³¸ë¬¸
    content = soup.select_one("article#dic_area").text.strip()

    # ê¸°ìëª… (ì—†ì„ ìˆ˜ ìˆìŒ)
    writer_tag = soup.select_one("em.media_end_head_journalist_name")
    writer = writer_tag.text.strip() if writer_tag else None

    # ì–¸ë¡ ì‚¬ (img altë‚˜ title ì†ì„±)
    press_tag = soup.select_one("img.media_end_head_top_logo_img")
    press = press_tag["title"].strip() if press_tag else None

    # ì‘ì„±ì¼ (ì‹œê°„)
    date_tag = soup.select_one("span.media_end_head_info_datestamp_time")
    date_str = date_tag["data-date-time"] if date_tag else None
    date = datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S") if date_str else None

    # í™•ì¸ ì¶œë ¥
    print("ğŸ“° ì œëª©:", title)
    print("ğŸ“ ê¸°ì:", writer)
    print("ğŸ¢ ì–¸ë¡ ì‚¬:", press)
    print("ğŸ“… ì‘ì„±ì¼:", date)
    print("ğŸ“„ ë³¸ë¬¸:\n", content)

    

if __name__ == "__main__":
    main()